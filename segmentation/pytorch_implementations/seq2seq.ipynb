{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "%matplotlib inline\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['je ne suis pas tres organise .', 'i m not very organized .']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 26s (- 66m 11s) (500 0%) 3.6595\n",
      "0m 49s (- 60m 40s) (1000 1%) 3.2997\n",
      "1m 11s (- 58m 25s) (1500 2%) 3.0578\n",
      "1m 32s (- 56m 17s) (2000 2%) 2.9008\n",
      "1m 54s (- 55m 25s) (2500 3%) 2.8358\n",
      "2m 19s (- 55m 37s) (3000 4%) 2.7721\n",
      "2m 41s (- 54m 52s) (3500 4%) 2.7639\n",
      "3m 2s (- 54m 6s) (4000 5%) 2.7258\n",
      "3m 24s (- 53m 20s) (4500 6%) 2.5227\n",
      "3m 46s (- 52m 48s) (5000 6%) 2.4637\n",
      "4m 8s (- 52m 18s) (5500 7%) 2.5554\n",
      "4m 30s (- 51m 54s) (6000 8%) 2.5272\n",
      "4m 53s (- 51m 28s) (6500 8%) 2.4777\n",
      "5m 14s (- 50m 57s) (7000 9%) 2.2890\n",
      "5m 37s (- 50m 39s) (7500 10%) 2.3113\n",
      "5m 59s (- 50m 7s) (8000 10%) 2.2056\n",
      "6m 21s (- 49m 40s) (8500 11%) 2.2161\n",
      "6m 43s (- 49m 18s) (9000 12%) 2.1928\n",
      "7m 4s (- 48m 49s) (9500 12%) 2.2201\n",
      "7m 27s (- 48m 27s) (10000 13%) 2.0653\n",
      "7m 49s (- 48m 3s) (10500 14%) 2.1673\n",
      "8m 11s (- 47m 41s) (11000 14%) 2.1520\n",
      "8m 34s (- 47m 18s) (11500 15%) 2.1144\n",
      "8m 55s (- 46m 52s) (12000 16%) 2.0693\n",
      "9m 17s (- 46m 26s) (12500 16%) 2.0307\n",
      "9m 39s (- 46m 4s) (13000 17%) 2.0242\n",
      "10m 1s (- 45m 39s) (13500 18%) 1.9776\n",
      "10m 23s (- 45m 18s) (14000 18%) 2.0430\n",
      "10m 45s (- 44m 53s) (14500 19%) 1.8544\n",
      "11m 7s (- 44m 28s) (15000 20%) 1.9397\n",
      "11m 29s (- 44m 5s) (15500 20%) 1.8644\n",
      "11m 51s (- 43m 43s) (16000 21%) 1.8751\n",
      "12m 13s (- 43m 22s) (16500 22%) 1.8008\n",
      "12m 36s (- 43m 2s) (17000 22%) 1.9018\n",
      "12m 59s (- 42m 39s) (17500 23%) 1.7611\n",
      "13m 21s (- 42m 18s) (18000 24%) 1.7944\n",
      "13m 44s (- 41m 58s) (18500 24%) 1.7375\n",
      "14m 6s (- 41m 35s) (19000 25%) 1.8140\n",
      "14m 30s (- 41m 17s) (19500 26%) 1.7114\n",
      "14m 54s (- 40m 59s) (20000 26%) 1.6997\n",
      "15m 17s (- 40m 37s) (20500 27%) 1.6635\n",
      "15m 39s (- 40m 16s) (21000 28%) 1.7006\n",
      "16m 2s (- 39m 54s) (21500 28%) 1.6439\n",
      "16m 24s (- 39m 31s) (22000 29%) 1.6132\n",
      "16m 47s (- 39m 9s) (22500 30%) 1.6845\n",
      "17m 10s (- 38m 49s) (23000 30%) 1.5423\n",
      "17m 34s (- 38m 29s) (23500 31%) 1.6081\n",
      "17m 58s (- 38m 10s) (24000 32%) 1.5033\n",
      "18m 20s (- 37m 48s) (24500 32%) 1.5671\n",
      "18m 42s (- 37m 25s) (25000 33%) 1.4873\n",
      "19m 4s (- 37m 2s) (25500 34%) 1.4459\n",
      "19m 27s (- 36m 39s) (26000 34%) 1.4675\n",
      "19m 49s (- 36m 17s) (26500 35%) 1.4581\n",
      "20m 11s (- 35m 53s) (27000 36%) 1.4025\n",
      "20m 33s (- 35m 30s) (27500 36%) 1.4464\n",
      "20m 55s (- 35m 7s) (28000 37%) 1.3937\n",
      "21m 17s (- 34m 44s) (28500 38%) 1.4345\n",
      "21m 39s (- 34m 21s) (29000 38%) 1.4195\n",
      "22m 1s (- 33m 58s) (29500 39%) 1.4063\n",
      "22m 23s (- 33m 35s) (30000 40%) 1.3593\n",
      "22m 46s (- 33m 13s) (30500 40%) 1.4080\n",
      "23m 8s (- 32m 51s) (31000 41%) 1.2958\n",
      "23m 31s (- 32m 28s) (31500 42%) 1.3641\n",
      "23m 53s (- 32m 6s) (32000 42%) 1.2678\n",
      "24m 16s (- 31m 44s) (32500 43%) 1.2893\n",
      "24m 38s (- 31m 22s) (33000 44%) 1.2996\n",
      "25m 1s (- 30m 59s) (33500 44%) 1.2709\n",
      "25m 23s (- 30m 37s) (34000 45%) 1.2662\n",
      "25m 46s (- 30m 15s) (34500 46%) 1.2510\n",
      "26m 8s (- 29m 52s) (35000 46%) 1.2031\n",
      "26m 31s (- 29m 31s) (35500 47%) 1.1909\n",
      "26m 55s (- 29m 9s) (36000 48%) 1.1924\n",
      "27m 18s (- 28m 48s) (36500 48%) 1.1548\n",
      "27m 42s (- 28m 26s) (37000 49%) 1.2123\n",
      "28m 4s (- 28m 4s) (37500 50%) 1.1044\n",
      "28m 27s (- 27m 42s) (38000 50%) 1.1307\n",
      "28m 50s (- 27m 20s) (38500 51%) 1.0954\n",
      "29m 13s (- 26m 58s) (39000 52%) 1.1217\n",
      "29m 36s (- 26m 36s) (39500 52%) 1.1802\n",
      "29m 59s (- 26m 14s) (40000 53%) 1.1391\n",
      "30m 24s (- 25m 54s) (40500 54%) 1.0474\n",
      "30m 47s (- 25m 32s) (41000 54%) 1.0586\n",
      "31m 11s (- 25m 10s) (41500 55%) 1.0842\n",
      "31m 35s (- 24m 49s) (42000 56%) 1.0145\n",
      "31m 58s (- 24m 26s) (42500 56%) 1.0252\n",
      "32m 21s (- 24m 4s) (43000 57%) 1.0680\n",
      "32m 44s (- 23m 42s) (43500 57%) 1.0340\n",
      "33m 7s (- 23m 20s) (44000 58%) 1.0234\n",
      "33m 29s (- 22m 57s) (44500 59%) 1.0587\n",
      "33m 52s (- 22m 34s) (45000 60%) 0.9623\n",
      "34m 15s (- 22m 12s) (45500 60%) 0.9215\n",
      "34m 38s (- 21m 50s) (46000 61%) 0.9865\n",
      "35m 2s (- 21m 28s) (46500 62%) 0.9577\n",
      "35m 26s (- 21m 6s) (47000 62%) 0.8763\n",
      "35m 51s (- 20m 45s) (47500 63%) 0.9735\n",
      "36m 16s (- 20m 24s) (48000 64%) 0.9812\n",
      "36m 40s (- 20m 2s) (48500 64%) 0.9402\n",
      "37m 4s (- 19m 40s) (49000 65%) 0.9155\n",
      "37m 26s (- 19m 17s) (49500 66%) 0.9139\n",
      "37m 51s (- 18m 55s) (50000 66%) 0.8714\n",
      "38m 13s (- 18m 32s) (50500 67%) 0.8847\n",
      "38m 35s (- 18m 9s) (51000 68%) 0.9192\n",
      "38m 57s (- 17m 46s) (51500 68%) 0.9309\n",
      "39m 19s (- 17m 23s) (52000 69%) 0.8355\n",
      "39m 41s (- 17m 0s) (52500 70%) 0.8403\n",
      "40m 3s (- 16m 37s) (53000 70%) 0.8640\n",
      "40m 25s (- 16m 14s) (53500 71%) 0.8503\n",
      "40m 47s (- 15m 51s) (54000 72%) 0.8834\n",
      "41m 9s (- 15m 28s) (54500 72%) 0.8124\n",
      "41m 31s (- 15m 5s) (55000 73%) 0.8411\n",
      "41m 55s (- 14m 43s) (55500 74%) 0.7595\n",
      "42m 18s (- 14m 21s) (56000 74%) 0.8943\n",
      "42m 41s (- 13m 58s) (56500 75%) 0.7995\n",
      "43m 5s (- 13m 36s) (57000 76%) 0.7515\n",
      "43m 28s (- 13m 13s) (57500 76%) 0.7756\n",
      "43m 50s (- 12m 51s) (58000 77%) 0.8176\n",
      "44m 13s (- 12m 28s) (58500 78%) 0.7925\n",
      "44m 37s (- 12m 6s) (59000 78%) 0.7479\n",
      "45m 1s (- 11m 43s) (59500 79%) 0.7376\n",
      "45m 24s (- 11m 21s) (60000 80%) 0.7658\n",
      "45m 48s (- 10m 58s) (60500 80%) 0.7086\n",
      "46m 12s (- 10m 36s) (61000 81%) 0.7727\n",
      "46m 35s (- 10m 13s) (61500 82%) 0.7471\n",
      "46m 58s (- 9m 50s) (62000 82%) 0.6882\n",
      "47m 22s (- 9m 28s) (62500 83%) 0.7268\n",
      "47m 46s (- 9m 6s) (63000 84%) 0.7703\n",
      "48m 10s (- 8m 43s) (63500 84%) 0.7249\n",
      "48m 34s (- 8m 20s) (64000 85%) 0.6722\n",
      "48m 55s (- 7m 57s) (64500 86%) 0.6316\n",
      "49m 15s (- 7m 34s) (65000 86%) 0.7238\n",
      "49m 35s (- 7m 11s) (65500 87%) 0.6474\n",
      "49m 54s (- 6m 48s) (66000 88%) 0.6669\n",
      "50m 15s (- 6m 25s) (66500 88%) 0.6857\n",
      "50m 34s (- 6m 2s) (67000 89%) 0.6450\n",
      "50m 54s (- 5m 39s) (67500 90%) 0.6763\n",
      "51m 15s (- 5m 16s) (68000 90%) 0.6569\n",
      "51m 34s (- 4m 53s) (68500 91%) 0.6296\n",
      "51m 54s (- 4m 30s) (69000 92%) 0.7304\n",
      "52m 15s (- 4m 8s) (69500 92%) 0.6244\n",
      "52m 35s (- 3m 45s) (70000 93%) 0.6694\n",
      "52m 57s (- 3m 22s) (70500 94%) 0.6164\n",
      "53m 17s (- 3m 0s) (71000 94%) 0.6366\n",
      "53m 37s (- 2m 37s) (71500 95%) 0.6238\n",
      "53m 56s (- 2m 14s) (72000 96%) 0.5882\n",
      "54m 17s (- 1m 52s) (72500 96%) 0.6657\n",
      "54m 37s (- 1m 29s) (73000 97%) 0.6037\n",
      "54m 57s (- 1m 7s) (73500 98%) 0.6435\n",
      "55m 17s (- 0m 44s) (74000 98%) 0.5933\n",
      "55m 37s (- 0m 22s) (74500 99%) 0.5421\n",
      "55m 57s (- 0m 0s) (75000 100%) 0.6265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bfe37ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmiFt3JVSqhn6fy462FtqfjwCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8bfe3840b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
