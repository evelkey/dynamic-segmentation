{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynet segmentation with tf fold\n",
    "![animation](../fold/tensorflow_fold/g3doc/animation.gif)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '.', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'Á', 'É', 'Í', 'Ó', 'Ö', 'Ú', 'Ü', 'á', 'é', 'í', 'ó', 'ö', 'ú', 'ü', 'Ő', 'ő', 'Ű', 'ű']\n"
     ]
    }
   ],
   "source": [
    "#just a bunch of fun\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "import tensorflow_fold as td\n",
    "from conv_lstm_cell import *\n",
    "\n",
    "# params\n",
    "symbol='0123456789-,;.!?:’\\”\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}'\n",
    "accent = 'áéíóöőúüű'\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "end_of_sentence = \".\"\n",
    "SPLIT_CHAR = '\\t'\n",
    "EMBEDDING_SIZE = 64\n",
    "\n",
    "#our alphabet\n",
    "hunabc = ' ' + alphabet + accent\n",
    "hunabc += hunabc.upper()\n",
    "hunabc += end_of_sentence\n",
    "vocabulary = sorted(set(hunabc))\n",
    "vsize=len(vocabulary)\n",
    "print(vocabulary)\n",
    "\n",
    "index = lambda char: vocabulary.index(char)\n",
    "char = lambda i: vocabulary[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_split(input_line, delimiter=''):\n",
    "    source, target = tf.string_split(input_line, delimiter=delimiter)\n",
    "    return source, target\n",
    "\n",
    "def decode(string):\n",
    "    string=str(string)\n",
    "    return string.decode('utf-8')\n",
    "\n",
    "def read_line(filename_queue):\n",
    "    global SPLIT_CHAR\n",
    "    reader = tf.TextLineReader(skip_header_lines=0)\n",
    "    _, csv_row = reader.read(filename_queue)\n",
    "    record_defaults = [[\"\"], [\"\"]]\n",
    "    source, target = tf.decode_csv(csv_row, record_defaults=record_defaults, field_delim=SPLIT_CHAR)\n",
    "    \n",
    "    return {\"in\": source,\"out\": target}\n",
    "\n",
    "def params_info():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(variable.name, shape)\n",
    "        # print(len(shape))\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            # print(dim)\n",
    "            variable_parametes *= dim.value\n",
    "        print(\"\\tparams: \", variable_parametes)\n",
    "        total_parameters += variable_parametes\n",
    "    print(total_parameters)\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filenames=[\"data.txt\"]\n",
    "filename_queue = tf.train.string_input_producer(filenames, num_epochs=1)\n",
    "data = read_line(filename_queue)\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "while not coord.should_stop():\n",
    "    try:\n",
    "        s= sess.run(data)\n",
    "        print(s[\"in\"].decode(\"utf-8\"))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m', 'a', 'l', 'ú']\n"
     ]
    }
   ],
   "source": [
    "length = td.Length()\n",
    "\n",
    "embedded =  (td.InputTransform(lambda s: [index(x) for x in s]) >> \n",
    "             td.Map(td.Scalar(tf.int32) >> \n",
    "             td.Function(td.Embedding(vsize, EMBEDDING_SIZE))))\n",
    "\n",
    "onehot = (td.InputTransform(lambda s: [index(x) for x in s]) >>\n",
    "          td.Map(td.Scalar(tf.int32) >>\n",
    "          td.Function(lambda indices: tf.one_hot(indices, depth=vsize)) >>\n",
    "          td.Function(lambda x: tf.reshape(x, [-1,vsize,1]))))\n",
    "\n",
    "decode_onehot = td.InputTransform(lambda s: [char(np.argmax(np.squeeze(x))) for x in s])\n",
    "\n",
    "print(decode_onehot.eval(onehot.eval(\"malú\")))\n",
    "#embedded.eval(\"kacsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_on_sequence(x, scope, kernel_size=3, input_channels=72, output_channels=72):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        filters = tf.get_variable(\"conv_filter\", [kernel_size] +  [input_channels, output_channels] , initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        bias = tf.get_variable(\"conv_bias\",  output_channels, initializer=tf.constant_initializer(0.05, dtype=tf.float32))\n",
    "        conv = tf.nn.conv1d(x, filters=filters, stride=1, padding='VALID')\n",
    "        return tf.nn.relu(tf.add(conv, bias))\n",
    "    \n",
    "def SeqToTuple(T, N):\n",
    "    return (td.InputTransform(lambda x: tuple(x))\n",
    "            .set_input_type(td.SequenceType(T))\n",
    "            .set_output_type(td.Tuple(*([T] * N))))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vec = td.Tensor([len(vocabulary)])\n",
    "data_segments = td.Map(vec) >> td.NGrams(3) \n",
    "\n",
    "b = td.Zeros([3,72]) >> td.ScopedLayer(conv1d_on_sequence)\n",
    "b.eval(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convlstm = Conv1DLSTMCell(input_shape=[vsize,1], output_channels=8, kernel_shape=[5])\n",
    "conv_lstm_cell_1d = td.ScopedLayer(convlstm)\n",
    "\n",
    "model = (td.Map(td.Tensor([vsize,1])) >>\n",
    "         td.RNN(conv_lstm_cell_1d) >>\n",
    "         td.GetItem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode =  onehot >> td.RNN(conv_lstm_cell_1d)\n",
    "out = encode.eval(\"aábúsúdfúősapioc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = td.RNN(conv_lstm_cell_1d,initial_state=(encode >> td.GetItem(1)),name='caucc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "block <td.Pipe> is already a child of <td.Pipe>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b7248e762921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monehot\u001b[0m \u001b[0;34m>>\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36m__rshift__\u001b[0;34m(self, rhs)\u001b[0m\n\u001b[1;32m    173\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;34m\"\"\"Function composition; `(a >> b).eval(x) => b(a(x))`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rrshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36mPipe\u001b[0;34m(*blocks, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mIdentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36m_pipe\u001b[0;34m(blocks, name)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m   \u001b[0;34m\"\"\"Internal implementation of Pipe.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m   \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComposition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m   \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m   \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, children, name)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_wires\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, children, input_type, output_type, name)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchildren\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/dynn/local/lib/python3.5/site-packages/tensorflow_fold/blocks/blocks.py\u001b[0m in \u001b[0;36m_add_child\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# internal consistency check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'block %s is already a child of %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: block <td.Pipe> is already a child of <td.Pipe>"
     ]
    }
   ],
   "source": [
    "model = onehot >> decode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
