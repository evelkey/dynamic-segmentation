{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynet segmentation with tf fold\n",
    "![animation](../../fold/tensorflow_fold/g3doc/animation.gif)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'C', 'D', 'E', 'G', 'L', 'N', 'S', 'T', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '²', '³', '¹', 'á', 'é', 'í', 'ó', 'ö', 'ú', 'ü', 'ő', 'ű']\n"
     ]
    }
   ],
   "source": [
    "#just a bunch of fun\n",
    "import numpy as np\n",
    "import six\n",
    "import time\n",
    "from multiprocessing import Process, Queue\n",
    "import time\n",
    "import data\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "import tensorflow_fold as td\n",
    "from conv_lstm_cell import *\n",
    "\n",
    "# params\n",
    "EMBEDDING_SIZE = 64\n",
    "SEP = \"|\"\n",
    "BATCH_SIZE = 100\n",
    "data_dir = \"/home/moon/data/\"\n",
    "\n",
    "#our alphabet\n",
    "\n",
    "vocabulary = data.vocabulary(data_dir + 'vocabulary')\n",
    "vsize=len(vocabulary)\n",
    "print(vocabulary)\n",
    "\n",
    "index = lambda char: vocabulary.index(char)\n",
    "char = lambda i: vocabulary[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data():\n",
    "    def __init__(self, folder):\n",
    "        self.data_dir = folder\n",
    "        self.data = dict()\n",
    "        self.size = dict()\n",
    "        self.datasets = [\"train\", \"test\", \"validation\"]\n",
    "        \n",
    "        for dataset in self.datasets:\n",
    "            self.data[dataset] = self.sentence_reader(folder+dataset)\n",
    "            self.size[dataset] = sum(1 for line in open(folder+dataset))\n",
    "\n",
    "                        \n",
    "    def sentence_reader(self, file):\n",
    "        \"\"\"\n",
    "        read sentences from the data format setence: word\\tword\\n.....\\t\\n\n",
    "        \"\"\"\n",
    "        i=0\n",
    "        while True:\n",
    "            sentence = []\n",
    "            end_sentence = False\n",
    "            with open(file) as f:\n",
    "                for lines in f:\n",
    "                    line = lines[:-1].split('\\t')\n",
    "                    if line[0] != \"\":\n",
    "                        sentence.append(line)\n",
    "                    else:\n",
    "                        end_sentence = True\n",
    "                    if end_sentence:\n",
    "                        end_sentence = False\n",
    "                        sent = \" \".join([word[0] for word in sentence])\n",
    "                        segmented = \" \".join([word[1].replace(\" \",\"|\") for word in sentence])\n",
    "                        tags = []\n",
    "                        last_char = \"_\"\n",
    "                        for char in segmented:\n",
    "                            if char != \"|\":\n",
    "                                tags.append(0 if last_char!=\"|\" else 1)\n",
    "                            last_char = char\n",
    "                        if len(sent) != 0:\n",
    "                            sent_onehot = self.onehot(sent)\n",
    "                            yield ([sent_onehot, sent_onehot[::-1]], tags)\n",
    "                            sentence = []\n",
    "                        \n",
    "          \n",
    "            \n",
    "    def onehot(self, string):\n",
    "        onehot = np.zeros([len(string),vsize])\n",
    "        indices = np.arange(len(string)), np.array([int(index(char)) for char in string])\n",
    "        onehot[indices]=1\n",
    "        return [onehot[i,:] for i in range(len(onehot))]\n",
    "            \n",
    "store = data(\"/home/moon/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_info():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        print(variable.name, shape)\n",
    "        # print(len(shape))\n",
    "        variable_parametes = 1\n",
    "        for dim in shape:\n",
    "            # print(dim)\n",
    "            variable_parametes *= dim.value\n",
    "        print(\"\\tparams: \", variable_parametes)\n",
    "        total_parameters += variable_parametes\n",
    "    print(total_parameters)\n",
    "    return total_parameters\n",
    "\n",
    "def onehot(string):\n",
    "    onehot = np.zeros([len(string),vsize])\n",
    "    onehot[np.arange(len(string)), np.array([index(char) for char in string])]=1\n",
    "    return [onehot[i,:] for i in range(len(onehot))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cell = td.ScopedLayer(tf.contrib.rnn.BasicLSTMCell(num_units=16), 'char_cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_conv_LSTM():\n",
    "    convlstm = Conv1DLSTMCell(input_shape=[vsize,1], output_channels=8, kernel_shape=[5])\n",
    "    conv_lstm_cell_1d = td.ScopedLayer(convlstm)\n",
    "\n",
    "    bidir_conv_lstm = td.Composition()\n",
    "    with bidir_conv_lstm.scope():\n",
    "        \n",
    "        forward = td.Identity().reads(bidir_conv_lstm.input[0])\n",
    "        backward = td.Identity().reads(bidir_conv_lstm.input[1])\n",
    "\n",
    "        forw = (td.RNN(conv_lstm_cell_1d) >>\n",
    "                td.GetItem(1) >>\n",
    "                td.GetItem(0) >> td.Function(lambda rnn_outs: tf.contrib.layers.flatten(rnn_outs))\n",
    "               ).reads(forward)\n",
    "\n",
    "        backw = (td.RNN(conv_lstm_cell_1d) >>\n",
    "                 td.GetItem(1) >>\n",
    "                 td.GetItem(0) >>\n",
    "                 td.Function(lambda rnn_outs: tf.contrib.layers.flatten(rnn_outs))).reads(backward)\n",
    "\n",
    "        rnn_outs = td.Concat().reads(forw,backw)\n",
    "        bidir_conv_lstm.output.reads(rnn_outs)\n",
    "    return bidir_conv_lstm >> td.FC(1)\n",
    "\n",
    "\n",
    "def FCNN():\n",
    "    return td.FC(50) >> td.FC(1)# >> td.Function(lambda xs: tf.squeeze(xs, axis=1))\n",
    "\n",
    "data = td.Record((td.Map(\n",
    "                        td.Vector(vsize) >>\n",
    "                        td.Function(lambda x: tf.reshape(x, [-1,vsize,1]))),\n",
    "                  td.Map(\n",
    "                        td.Vector(vsize) >>\n",
    "                        td.Function(lambda x: tf.reshape(x, [-1,vsize,1])))))\n",
    "bidir =  data >> bidirectional_conv_LSTM()\n",
    "#fc = FCNN()\n",
    "blk = bidir# >> fc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler = td.Compiler.create((blk, td.Scalar()))\n",
    "model_output, target = compiler.output_tensors\n",
    "loss = tf.nn.l2_loss(model_output - target)\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = opt.minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for i in range(100):\n",
    "    loff, _ = sess.run([loss, train_op], compiler.build_feed_dict([([onehot(\"aa\"), onehot(\"bbf\")],0.5) for _ in range(100)]))\n",
    "    losses.append(loss)\n",
    "    if i%10==0:\n",
    "        print(loff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run([model_output], compiler.build_feed_dict([[[onehot(\"aa\"), onehot(\"bbf\")],1] for _ in range(1)]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reverse = (td.Map(td.Scalar()) >> Slice(step=-1))\n",
    "\n",
    "def bi():\n",
    "    out_features = 64\n",
    "    convlstm = Conv1DLSTMCell(input_shape=[vsize,1], output_channels=out_features, kernel_shape=[vsize])\n",
    "    conv_lstm_cell_1d = td.ScopedLayer(convlstm)\n",
    "\n",
    "    bidir_conv_lstm = td.Composition()\n",
    "    with bidir_conv_lstm.scope():        \n",
    "        fw_seq = td.Identity().reads(bidir_conv_lstm.input)\n",
    "        bw_seq = td.Slice(step=-1).reads(fw_seq)\n",
    "\n",
    "        forward_dir = (td.RNN(conv_lstm_cell_1d) >> td.GetItem(0)).reads(fw_seq)\n",
    "\n",
    "        back_dir = (td.RNN(conv_lstm_cell_1d) >> td.GetItem(0)).reads(bw_seq)\n",
    "        \n",
    "        back_to_leftright = td.Slice(step=-1).reads(back_dir)\n",
    "        \n",
    "        output_transform = (td.Function(lambda x: tf.reshape(x, [-1,vsize*out_features])) >>\n",
    "                            td.FC(10) >>\n",
    "                            td.FC(1))\n",
    "        \n",
    "        bidir_common = (td.ZipWith(td.Concat() >> \n",
    "                                  output_transform >> \n",
    "                                  td.Metric('logits'))).reads(forward_dir, back_to_leftright)\n",
    "                    \n",
    "        #tag_logits = td.Map(output_transform).reads(bidir_common)\n",
    "\n",
    "        bidir_conv_lstm.output.reads(bidir_common)\n",
    "    return bidir_conv_lstm\n",
    "\n",
    "\n",
    "data = td.Map(td.Vector(vsize) >> td.Function(lambda x: tf.reshape(x, [-1,vsize,1])))\n",
    "\n",
    "model =  data >> bi() >> td.Void()\n",
    "labels = td.Map(td.Scalar() >> td.Metric(\"labels\")) >> td.Void()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moon/Envs/tf1/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "compiler = td.Compiler.create((model, labels))\n",
    "\n",
    "loss = tf.nn.l2_loss(compiler.metric_tensors['labels'] - compiler.metric_tensors['logits'])\n",
    "opt = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "train_op = opt.minimize(loss)\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00220643]\n",
      " [ 0.00760484]\n",
      " [ 0.00416973]\n",
      " [ 0.00292062]\n",
      " [ 0.00477531]] 4.95692\n",
      "[[ 0.02287579]\n",
      " [ 0.057783  ]\n",
      " [ 0.07244746]\n",
      " [ 0.09886152]\n",
      " [ 0.11806049]] 4.342\n",
      "[[ 0.04844023]\n",
      " [ 0.11468513]\n",
      " [ 0.15359043]\n",
      " [ 0.20911664]\n",
      " [ 0.25825381]] 3.80561\n",
      "[[ 0.07689697]\n",
      " [ 0.18113592]\n",
      " [ 0.25709108]\n",
      " [ 0.36086401]\n",
      " [ 0.47587466]] 3.45002\n",
      "[[ 0.10772377]\n",
      " [ 0.25519133]\n",
      " [ 0.3773036 ]\n",
      " [ 0.53262156]\n",
      " [ 0.75097859]] 3.61921\n",
      "[[ 0.1256361 ]\n",
      " [ 0.28107011]\n",
      " [ 0.38721466]\n",
      " [ 0.47888273]\n",
      " [ 0.6281032 ]] 3.36959\n",
      "[[ 0.14048012]\n",
      " [ 0.29696044]\n",
      " [ 0.382002  ]\n",
      " [ 0.41087475]\n",
      " [ 0.51979142]] 3.2319\n",
      "[[ 0.15524819]\n",
      " [ 0.31215006]\n",
      " [ 0.38015923]\n",
      " [ 0.35987121]\n",
      " [ 0.45867768]] 3.18267\n",
      "[[ 0.17076042]\n",
      " [ 0.32905355]\n",
      " [ 0.38440377]\n",
      " [ 0.32592076]\n",
      " [ 0.42950031]] 3.16046\n",
      "[[ 0.18716422]\n",
      " [ 0.34842092]\n",
      " [ 0.39514261]\n",
      " [ 0.30741882]\n",
      " [ 0.42257553]] 3.14266\n",
      "[[ 0.20429911]\n",
      " [ 0.37006199]\n",
      " [ 0.41148293]\n",
      " [ 0.30194876]\n",
      " [ 0.43096167]] 3.12475\n",
      "[[ 0.22180177]\n",
      " [ 0.39293176]\n",
      " [ 0.43104634]\n",
      " [ 0.3056289 ]\n",
      " [ 0.44788119]] 3.10992\n",
      "[[ 0.23913813]\n",
      " [ 0.41526803]\n",
      " [ 0.45025522]\n",
      " [ 0.31356609]\n",
      " [ 0.46645936]] 3.10131\n",
      "[[ 0.25564981]\n",
      " [ 0.43488222]\n",
      " [ 0.46503773]\n",
      " [ 0.32072359]\n",
      " [ 0.48029289]] 3.09754\n",
      "[[ 0.27069941]\n",
      " [ 0.44977519]\n",
      " [ 0.47205919]\n",
      " [ 0.32325795]\n",
      " [ 0.4849014 ]] 3.09372\n",
      "[[ 0.28388658]\n",
      " [ 0.45885074]\n",
      " [ 0.46990153]\n",
      " [ 0.31977773]\n",
      " [ 0.47916654]] 3.08634\n",
      "[[ 0.29516935]\n",
      " [ 0.46220315]\n",
      " [ 0.45933628]\n",
      " [ 0.31153613]\n",
      " [ 0.46536297]] 3.07619\n",
      "[[ 0.30481696]\n",
      " [ 0.46092239]\n",
      " [ 0.44283345]\n",
      " [ 0.30172178]\n",
      " [ 0.44802535]] 3.06643\n",
      "[[ 0.31327441]\n",
      " [ 0.45670903]\n",
      " [ 0.42384899]\n",
      " [ 0.29445693]\n",
      " [ 0.43250859]] 3.05876\n",
      "[[ 0.32101279]\n",
      " [ 0.45141125]\n",
      " [ 0.40595305]\n",
      " [ 0.29351425]\n",
      " [ 0.42329299]] 3.052\n",
      "[[ 0.32839888]\n",
      " [ 0.44648674]\n",
      " [ 0.39176092]\n",
      " [ 0.30086946]\n",
      " [ 0.4221873 ]] 3.04419\n",
      "[[ 0.33561486]\n",
      " [ 0.4425981 ]\n",
      " [ 0.3822419 ]\n",
      " [ 0.31605247]\n",
      " [ 0.427679  ]] 3.03522\n",
      "[[ 0.34265462]\n",
      " [ 0.43958485]\n",
      " [ 0.37689203]\n",
      " [ 0.33668843]\n",
      " [ 0.4358753 ]] 3.02671\n",
      "[[ 0.34938437]\n",
      " [ 0.43673414]\n",
      " [ 0.37442499]\n",
      " [ 0.35954657]\n",
      " [ 0.44199005]] 3.01991\n",
      "[[ 0.35563955]\n",
      " [ 0.4331685 ]\n",
      " [ 0.37351611]\n",
      " [ 0.38151857]\n",
      " [ 0.44158381]] 3.0146\n",
      "[[ 0.36133426]\n",
      " [ 0.42825583]\n",
      " [ 0.37341255]\n",
      " [ 0.40033829]\n",
      " [ 0.43156806]] 3.00999\n",
      "[[ 0.36654395]\n",
      " [ 0.42196375]\n",
      " [ 0.37428606]\n",
      " [ 0.41479474]\n",
      " [ 0.41129959]] 3.00652\n",
      "[[ 0.37151739]\n",
      " [ 0.41507521]\n",
      " [ 0.37718135]\n",
      " [ 0.42410922]\n",
      " [ 0.38360322]] 3.00602\n",
      "[[ 0.37660033]\n",
      " [ 0.40918985]\n",
      " [ 0.38350904]\n",
      " [ 0.42672148]\n",
      " [ 0.36036441]] 3.00797\n",
      "[[ 0.38202456]\n",
      " [ 0.40587431]\n",
      " [ 0.3939577 ]\n",
      " [ 0.42057863]\n",
      " [ 0.35724956]] 3.00661\n",
      "[[ 0.38771236]\n",
      " [ 0.40512097]\n",
      " [ 0.40758514]\n",
      " [ 0.4063651 ]\n",
      " [ 0.37889928]] 3.0018\n",
      "[[ 0.39326543]\n",
      " [ 0.40512174]\n",
      " [ 0.42124227]\n",
      " [ 0.38871062]\n",
      " [ 0.41622815]] 3.00228\n",
      "[[ 0.39807028]\n",
      " [ 0.40370038]\n",
      " [ 0.42898959]\n",
      " [ 0.3754845 ]\n",
      " [ 0.44290775]] 3.00825\n",
      "[[ 0.40170616]\n",
      " [ 0.40014163]\n",
      " [ 0.42596072]\n",
      " [ 0.37515384]\n",
      " [ 0.43347856]] 3.00604\n",
      "[[ 0.40443432]\n",
      " [ 0.39546314]\n",
      " [ 0.41488102]\n",
      " [ 0.38616031]\n",
      " [ 0.39621657]] 3.00117\n",
      "[[ 0.40693438]\n",
      " [ 0.39191532]\n",
      " [ 0.4030644 ]\n",
      " [ 0.40063655]\n",
      " [ 0.36232734]] 3.00386\n",
      "[[ 0.40967539]\n",
      " [ 0.39175794]\n",
      " [ 0.39617243]\n",
      " [ 0.40991613]\n",
      " [ 0.35735852]] 3.00523\n",
      "[[ 0.4126257 ]\n",
      " [ 0.39486569]\n",
      " [ 0.39508078]\n",
      " [ 0.41175994]\n",
      " [ 0.38075548]] 3.0018\n",
      "[[ 0.41533428]\n",
      " [ 0.39878061]\n",
      " [ 0.3968806 ]\n",
      " [ 0.40925953]\n",
      " [ 0.41369909]] 3.0013\n",
      "[[ 0.41719675]\n",
      " [ 0.40085015]\n",
      " [ 0.39704499]\n",
      " [ 0.40568307]\n",
      " [ 0.43569314]] 3.00403\n",
      "[[ 0.41785747]\n",
      " [ 0.39990774]\n",
      " [ 0.39267889]\n",
      " [ 0.40271688]\n",
      " [ 0.43581814]] 3.00416\n",
      "[[ 0.41748324]\n",
      " [ 0.39663932]\n",
      " [ 0.38492405]\n",
      " [ 0.40079412]\n",
      " [ 0.4176563 ]] 3.00214\n",
      "[[ 0.41663012]\n",
      " [ 0.39297882]\n",
      " [ 0.37782171]\n",
      " [ 0.39982247]\n",
      " [ 0.39409974]] 3.00213\n",
      "[[ 0.41587836]\n",
      " [ 0.3910881 ]\n",
      " [ 0.37540549]\n",
      " [ 0.39948913]\n",
      " [ 0.37873828]] 3.00347\n",
      "[[ 0.41553047]\n",
      " [ 0.39214817]\n",
      " [ 0.3793951 ]\n",
      " [ 0.39942092]\n",
      " [ 0.37910837]] 3.00291\n",
      "[[ 0.41550216]\n",
      " [ 0.39565846]\n",
      " [ 0.38853708]\n",
      " [ 0.39956048]\n",
      " [ 0.39333233]] 3.00109\n",
      "[[ 0.4154008 ]\n",
      " [ 0.39981371]\n",
      " [ 0.39930996]\n",
      " [ 0.40007383]\n",
      " [ 0.41165158]] 3.00093\n",
      "[[ 0.41474962]\n",
      " [ 0.40260044]\n",
      " [ 0.40750784]\n",
      " [ 0.4009648 ]\n",
      " [ 0.42188564]] 3.0019\n",
      "[[ 0.41329345]\n",
      " [ 0.40292135]\n",
      " [ 0.41060099]\n",
      " [ 0.40191978]\n",
      " [ 0.41723374]] 3.0015\n",
      "[[ 0.41117784]\n",
      " [ 0.40112004]\n",
      " [ 0.40923437]\n",
      " [ 0.40234938]\n",
      " [ 0.40123188]] 3.00055\n",
      "[[ 0.40883231]\n",
      " [ 0.39865831]\n",
      " [ 0.40623868]\n",
      " [ 0.40166861]\n",
      " [ 0.38473293]] 3.00089\n",
      "[[ 0.40668702]\n",
      " [ 0.39715877]\n",
      " [ 0.4043617 ]\n",
      " [ 0.39974833]\n",
      " [ 0.37808514]] 3.00138\n",
      "[[ 0.40494719]\n",
      " [ 0.39734888]\n",
      " [ 0.40464288]\n",
      " [ 0.39729697]\n",
      " [ 0.3843407 ]] 3.00076\n",
      "[[ 0.40353805]\n",
      " [ 0.39873558]\n",
      " [ 0.40616763]\n",
      " [ 0.39554214]\n",
      " [ 0.39818424]] 3.00019\n",
      "[[ 0.40221134]\n",
      " [ 0.40018514]\n",
      " [ 0.40692759]\n",
      " [ 0.39531863]\n",
      " [ 0.41051596]] 3.00046\n",
      "[[ 0.40074319]\n",
      " [ 0.40076426]\n",
      " [ 0.40529454]\n",
      " [ 0.39656588]\n",
      " [ 0.41456804]] 3.00063\n",
      "[[ 0.39910132]\n",
      " [ 0.40025905]\n",
      " [ 0.40122539]\n",
      " [ 0.39859843]\n",
      " [ 0.40965429]] 3.00024\n",
      "[[ 0.39746091]\n",
      " [ 0.39918631]\n",
      " [ 0.39622867]\n",
      " [ 0.40072042]\n",
      " [ 0.40032002]] 3.00005\n",
      "[[ 0.39607859]\n",
      " [ 0.39840233]\n",
      " [ 0.39230177]\n",
      " [ 0.40256301]\n",
      " [ 0.3925679 ]] 3.00035\n",
      "[[ 0.39513728]\n",
      " [ 0.39855453]\n",
      " [ 0.39080676]\n",
      " [ 0.40397823]\n",
      " [ 0.39041528]] 3.00054\n",
      "[[ 0.39465657]\n",
      " [ 0.39969483]\n",
      " [ 0.39190701]\n",
      " [ 0.4048073 ]\n",
      " [ 0.39431471]] 3.00037\n",
      "[[ 0.3944985 ]\n",
      " [ 0.40128088]\n",
      " [ 0.39465582]\n",
      " [ 0.40478143]\n",
      " [ 0.40153223]] 3.00021\n",
      "[[ 0.39445025]\n",
      " [ 0.40252885]\n",
      " [ 0.39756173]\n",
      " [ 0.40364423]\n",
      " [ 0.40788835]] 3.0003\n",
      "[[ 0.39434287]\n",
      " [ 0.40288118]\n",
      " [ 0.39937469]\n",
      " [ 0.4014433 ]\n",
      " [ 0.40998015]] 3.00036\n",
      "[[ 0.39414215]\n",
      " [ 0.40231618]\n",
      " [ 0.39972466]\n",
      " [ 0.39873007]\n",
      " [ 0.40692291]] 3.00022\n",
      "[[ 0.39395681]\n",
      " [ 0.40133762]\n",
      " [ 0.39922279]\n",
      " [ 0.39641783]\n",
      " [ 0.40069604]] 3.00013\n",
      "[[ 0.39395857]\n",
      " [ 0.40067035]\n",
      " [ 0.39896345]\n",
      " [ 0.39535654]\n",
      " [ 0.39486548]] 3.00021\n",
      "[[ 0.39426869]\n",
      " [ 0.40083733]\n",
      " [ 0.39977765]\n",
      " [ 0.39590701]\n",
      " [ 0.3924706 ]] 3.00027\n",
      "[[ 0.39487985]\n",
      " [ 0.40185151]\n",
      " [ 0.40170974]\n",
      " [ 0.39776009]\n",
      " [ 0.39433804]] 3.00017\n",
      "[[ 0.39565387]\n",
      " [ 0.40320259]\n",
      " [ 0.40398726]\n",
      " [ 0.40007108]\n",
      " [ 0.39877772]] 3.00012\n",
      "[[ 0.39639291]\n",
      " [ 0.40414944]\n",
      " [ 0.40546873]\n",
      " [ 0.40183133]\n",
      " [ 0.40277922]] 3.00018\n",
      "[[ 0.39694491]\n",
      " [ 0.40414789]\n",
      " [ 0.40532026]\n",
      " [ 0.40233335]\n",
      " [ 0.40393904]] 3.00019\n",
      "[[ 0.39728317]\n",
      " [ 0.40315458]\n",
      " [ 0.403523  ]\n",
      " [ 0.4015069 ]\n",
      " [ 0.4018952 ]] 3.00009\n",
      "[[ 0.39750808]\n",
      " [ 0.40162724]\n",
      " [ 0.40087515]\n",
      " [ 0.39991358]\n",
      " [ 0.39836332]] 3.00003\n",
      "[[ 0.39777437]\n",
      " [ 0.40023994]\n",
      " [ 0.3985067 ]\n",
      " [ 0.39841133]\n",
      " [ 0.39586213]] 3.00007\n",
      "[[ 0.39819419]\n",
      " [ 0.39949986]\n",
      " [ 0.39725104]\n",
      " [ 0.39770788]\n",
      " [ 0.39606968]] 3.00008\n",
      "[[ 0.39877594]\n",
      " [ 0.39949721]\n",
      " [ 0.39725634]\n",
      " [ 0.3980495 ]\n",
      " [ 0.39885217]] 3.00004\n",
      "[[ 0.39942807]\n",
      " [ 0.39991659]\n",
      " [ 0.39801419]\n",
      " [ 0.39917049]\n",
      " [ 0.40246886]] 3.00003\n",
      "[[ 0.40001935]\n",
      " [ 0.40027589]\n",
      " [ 0.39875305]\n",
      " [ 0.40049458]\n",
      " [ 0.4047251 ]] 3.00006\n",
      "[[ 0.40045753]\n",
      " [ 0.40022969]\n",
      " [ 0.39894393]\n",
      " [ 0.40146488]\n",
      " [ 0.40434012]] 3.00006\n",
      "[[ 0.40073815]\n",
      " [ 0.39975804]\n",
      " [ 0.39860681]\n",
      " [ 0.40180668]\n",
      " [ 0.40169302]] 3.00002\n",
      "[[ 0.40093359]\n",
      " [ 0.39913678]\n",
      " [ 0.39822456]\n",
      " [ 0.40157923]\n",
      " [ 0.39850432]] 3.00002\n",
      "[[ 0.40113491]\n",
      " [ 0.39872593]\n",
      " [ 0.39835614]\n",
      " [ 0.40103501]\n",
      " [ 0.39670414]] 3.00004\n",
      "[[ 0.40138793]\n",
      " [ 0.39872265]\n",
      " [ 0.39923054]\n",
      " [ 0.40042892]\n",
      " [ 0.39722437]] 3.00003\n",
      "[[ 0.40166619]\n",
      " [ 0.3990455 ]\n",
      " [ 0.40058014]\n",
      " [ 0.39990416]\n",
      " [ 0.39946991]] 3.00001\n",
      "[[ 0.40189275]\n",
      " [ 0.39941627]\n",
      " [ 0.40180376]\n",
      " [ 0.39949259]\n",
      " [ 0.40178406]] 3.00003\n",
      "[[ 0.40199584]\n",
      " [ 0.39957029]\n",
      " [ 0.40234903]\n",
      " [ 0.3991923 ]\n",
      " [ 0.40259412]] 3.00004\n",
      "[[ 0.40195855]\n",
      " [ 0.39943919]\n",
      " [ 0.40206048]\n",
      " [ 0.39904231]\n",
      " [ 0.40145826]] 3.00003\n",
      "[[ 0.40182859]\n",
      " [ 0.3991819 ]\n",
      " [ 0.40124974]\n",
      " [ 0.39912444]\n",
      " [ 0.39928579]] 3.00002\n",
      "[[ 0.40168232]\n",
      " [ 0.39905393]\n",
      " [ 0.40044832]\n",
      " [ 0.39948881]\n",
      " [ 0.39761174]] 3.00002\n",
      "[[ 0.40157178]\n",
      " [ 0.39921394]\n",
      " [ 0.40004274]\n",
      " [ 0.40006855]\n",
      " [ 0.39750922]] 3.00002\n",
      "[[ 0.40149388]\n",
      " [ 0.39960712]\n",
      " [ 0.40005243]\n",
      " [ 0.40066075]\n",
      " [ 0.39892027]] 3.00001\n",
      "[[ 0.4013994 ]\n",
      " [ 0.40000746]\n",
      " [ 0.40017942]\n",
      " [ 0.40100411]\n",
      " [ 0.40080953]] 3.00001\n",
      "[[ 0.40123427]\n",
      " [ 0.40018046]\n",
      " [ 0.40006915]\n",
      " [ 0.40092179]\n",
      " [ 0.40194589]] 3.00002\n",
      "[[ 0.40098241]\n",
      " [ 0.40004748]\n",
      " [ 0.39958912]\n",
      " [ 0.40044424]\n",
      " [ 0.40173274]] 3.00001\n",
      "[[ 0.40068057]\n",
      " [ 0.39973643]\n",
      " [ 0.39893243]\n",
      " [ 0.39981619]\n",
      " [ 0.40052897]] 3.00001\n",
      "[[ 0.40039533]\n",
      " [ 0.39948988]\n",
      " [ 0.39847714]\n",
      " [ 0.39936545]\n",
      " [ 0.39929888]] 3.00001\n",
      "[[ 0.40018097]\n",
      " [ 0.39949998]\n",
      " [ 0.39852014]\n",
      " [ 0.39931476]\n",
      " [ 0.39889279]] 3.00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.40004751]\n",
      " [ 0.39978489]\n",
      " [ 0.39907438]\n",
      " [ 0.39965689]\n",
      " [ 0.39947927]] 3.0\n",
      "[[ 0.3999595 ]\n",
      " [ 0.40018547]\n",
      " [ 0.39986482]\n",
      " [ 0.40016884]\n",
      " [ 0.40049672]] 3.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    a,b,c= sess.run([compiler.metric_tensors['logits'], loss, train_op],compiler.build_feed_dict([(onehot(\"value\"),[1.0,0.0,1.0,0.0,0.0])]))\n",
    "    print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
