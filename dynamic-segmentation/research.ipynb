{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynet segmentation with tf fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just a bunch of fun\n",
    "import numpy as np\n",
    "import six\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "import tensorflow_fold as td\n",
    "\n",
    "# params\n",
    "symbol='0123456789-,;.!?:’\\”\\\"/\\\\|_@#$%^&*~`+ =<>()[]{}'\n",
    "accent = 'áéíóöőúüű'\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "end_of_sentence = \".\"\n",
    "SPLIT_CHAR = '\\t'\n",
    "\n",
    "#our alphabet\n",
    "hunabc = ' ' + alphabet + accent\n",
    "hunabc += hunabc.upper()\n",
    "hunabc += end_of_sentence\n",
    "vocabulary = sorted(set(hunabc))\n",
    "print(vocabulary)\n",
    "\n",
    "index = lambda char: vocabulary.index(char)\n",
    "char = lambda i: vocabulary[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_split(input_line, delimiter=''):\n",
    "    source, target = tf.string_split(input_line, delimiter=delimiter)\n",
    "    return source, target\n",
    "\n",
    "def decode(string):\n",
    "    string=str(string)\n",
    "    return string.decode('utf-8')\n",
    "\n",
    "def read_line(filename_queue):\n",
    "    global SPLIT_CHAR\n",
    "    reader = tf.TextLineReader(skip_header_lines=0)\n",
    "    _, csv_row = reader.read(filename_queue)\n",
    "    record_defaults = [[\"\"], [\"\"]]\n",
    "    source, target = tf.decode_csv(csv_row, record_defaults=record_defaults, field_delim=SPLIT_CHAR)\n",
    "    \n",
    "    return {\"in\": source,\"out\": target}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "áááááááááááá\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n",
      "egy valami cucc\n",
      "harom valami cucc\n"
     ]
    }
   ],
   "source": [
    "filenames=[\"data.txt\"]\n",
    "filename_queue = tf.train.string_input_producer(filenames, num_epochs=1)\n",
    "data = read_line(filename_queue)\n",
    "\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "while not coord.should_stop():\n",
    "    try:\n",
    "        s= sess.run(data)\n",
    "        print(s[\"in\"].decode(\"utf-8\"))\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0, dtype=int32), array(28, dtype=int32), array(29, dtype=int32), array(30, dtype=int32), array(31, dtype=int32), array(32, dtype=int32), array(33, dtype=int32)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oneblock = td.OneHot(len(vocabulary), dtype='float32', name=\"onehot_encoder\")\n",
    "length = td.Length()\n",
    "\n",
    "\n",
    "demo_word=[\"a\",\"e\",\"k\"]\n",
    "inputs =  td.InputTransform(lambda s: [index(x) for x in s]) >> td.Map(td.Scalar('int32')) #>> td.Function(td.Embedding(128, 8))\n",
    "print(inputs.eval(\" abcdef\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_on_variable_sequence(x, scope, kernel_size=3, input_channels=71, output_channels=71):\n",
    "    with tf.variable_scope(scope) as sc:\n",
    "        filter = tf.get_variable(\"conv_filter\", [kernel_size] +  [input_channels, output_channels] , initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        bias = tf.get_variable(\"conv_bias\",  output_channels, initializer=tf.constant_initializer(0.05, dtype=tf.float32))\n",
    "        conv = tf.nn.conv1d(x, filters=filter, stride=1, padding='SAME')\n",
    "        return tf.nn.relu(tf.add(conv, bias))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = td.Tensor([len(vocabulary)])\n",
    "a = td.Map(vec) >> td.NGrams(3)\n",
    "a.eval([oneblock.eval(\"k\"),oneblock.eval(\"a\"),oneblock.eval(\"c\"),oneblock.eval(\"s\"),oneblock.eval(\"a\")])\n",
    "b = td.Zeros([3,71]) >> td.ScopedLayer(conv1d_on_variable_sequence)\n",
    "c = a >> td.GetItem(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05],\n",
       "       [ 0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05],\n",
       "       [ 0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,\n",
       "         0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05,  0.05]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.eval([oneblock.eval(\"k\"),oneblock.eval(\"a\"),oneblock.eval(\"c\"),oneblock.eval(\"s\"),oneblock.eval(\"a\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
